{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imdb dataset RNN classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saumitra-Shukla/Imdb_dataset_RNN_classification/blob/master/Imdb_dataset_RNN_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToERchl-L-bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnFzOAY_PZzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy==1.16.2\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sx6nfPMVzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense,Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u_yDhsVMwPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=10000)\n",
        "\n",
        "\n",
        "x_train=sequence.pad_sequences(x_train,maxlen=50)\n",
        "x_test=sequence.pad_sequences(x_test,maxlen=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yppx5DdYP7EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(10000,32))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(SimpleRNN(32))\n",
        "#model.add(Dropout(0.2))\n",
        "          \n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "history=model.fit(x_train,y_train,epochs=5,batch_size=128,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPaA1gHtyEP4",
        "colab_type": "code",
        "outputId": "8ee1c9ef-9432-4c29-bc3c-8a39177ca421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(10000,32))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(LSTM(32,activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "          \n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
        "history=model.fit(x_train,y_train,epochs=10,batch_size=128,validation_split=0.2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 17s 828us/sample - loss: 0.5976 - acc: 0.7059 - val_loss: 0.5175 - val_acc: 0.7684\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 16s 813us/sample - loss: 0.4396 - acc: 0.8228 - val_loss: 0.4431 - val_acc: 0.8088\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 15s 767us/sample - loss: 0.3672 - acc: 0.8468 - val_loss: 0.4307 - val_acc: 0.8070\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 16s 776us/sample - loss: 0.3313 - acc: 0.8630 - val_loss: 0.4253 - val_acc: 0.7990\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 16s 778us/sample - loss: 0.3002 - acc: 0.8759 - val_loss: 0.4282 - val_acc: 0.8126\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 16s 777us/sample - loss: 0.2764 - acc: 0.8850 - val_loss: 0.5509 - val_acc: 0.7560\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 16s 781us/sample - loss: 0.2618 - acc: 0.8921 - val_loss: 0.4323 - val_acc: 0.8030\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 15s 770us/sample - loss: 0.2540 - acc: 0.9016 - val_loss: 0.5096 - val_acc: 0.7906\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 15s 765us/sample - loss: 0.2329 - acc: 0.9050 - val_loss: 0.6326 - val_acc: 0.8020\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 15s 765us/sample - loss: 0.2221 - acc: 0.9117 - val_loss: 0.5257 - val_acc: 0.8066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GLeJGLtypHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_los=history.history['val_loss']\n",
        "\n",
        "epochs= range(len(acc))\n",
        "\n",
        "plt.plot(epochs,acc,'bo',label='Training_acc')\n",
        "plt.plot(epochs,val_acc,'b',label='Validation_acc')\n",
        "\n",
        "plt.title('training acc')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs,loss,'bo',label='Training_loss')\n",
        "plt.plot(epochs,val_loss,'b',label='Validation_loss')\n",
        "plt.title('training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6EPiIFNYxZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction=model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd3ir8apZ529",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c6277e85-9fd0-4c00-d460-effa923f745d"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.08307886]\n",
            " [0.9506738 ]\n",
            " [0.9318675 ]\n",
            " ...\n",
            " [0.2586537 ]\n",
            " [0.01932457]\n",
            " [0.36284864]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XmnW6xPejsE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2d38be41-979c-4c0e-8c16-90e35daaf944"
      },
      "source": [
        "print(x_test[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 394  354    4  123    9 1035 1035 1035   10   10   13   92  124   89\n",
            "  488 7944  100   28 1668   14   31   23   27 7479   29  220  468    8\n",
            "  124   14  286  170    8  157   46    5   27  239   16  179    2   38\n",
            "   32   25 7944  451  202   14    6  717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4j_FKywerU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(z_train,yy_train),(z_test,yy_test)=imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy-ehz_5e329",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f4862667-b065-4ce9-e16c-ffe3e3b2b0de"
      },
      "source": [
        "print(z_test[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iMMy98re-eb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7308bd1f-3547-4a51-e13a-98d83761a98e"
      },
      "source": [
        "import keras\n",
        "NUM_WORDS=1000 # only use top 1000 words\n",
        "INDEX_FROM=3   # word index offset\n",
        "\n",
        "train,test = keras.datasets.imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
        "train_x,train_y = train\n",
        "test_x,test_y = test\n",
        "\n",
        "word_to_id = keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "print(' '.join(id_to_word[id] for id in test_x[1] ))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> this film <UNK> a lot of <UNK> because it <UNK> on <UNK> and character development the plot is very simple and many of the scenes take place on the same set in <UNK> <UNK> the <UNK> <UNK> character <UNK> but the film <UNK> to a <UNK> <UNK> br br the characters create an atmosphere <UNK> with sexual <UNK> and <UNK> <UNK> it's very interesting that robert <UNK> directed this <UNK> the style and <UNK> of his other films still the <UNK> <UNK> <UNK> style is <UNK> here and there i think what really makes this film work is the brilliant performance by <UNK> <UNK> it's definitely one of her <UNK> characters but she plays it so perfectly and <UNK> that it's scary michael <UNK> does a good job as the <UNK> young man <UNK> <UNK> <UNK> michael <UNK> has a small part the <UNK> <UNK> set <UNK> the <UNK> of the story very well in short this movie is a powerful <UNK> of <UNK> sexual <UNK> and <UNK> be <UNK> <UNK> up the atmosphere and pay attention to the <UNK> written script br br i <UNK> robert <UNK> this is one of his many films that <UNK> with <UNK> <UNK> subject matter this film is <UNK> but it's <UNK> and it's sure to <UNK> a strong emotional <UNK> from the viewer if you want to see an <UNK> film some might even say <UNK> this is worth the time br br unfortunately it's very difficult to find in video <UNK> you may have to buy it off the <UNK>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5UMDn-pffBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// prediction of my data sets\n",
        "\n",
        "data_sets=['this movie was very bad', 'this movie was very good','this movie was nice', 'this movie was ok', 'this movie was not bad']"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}